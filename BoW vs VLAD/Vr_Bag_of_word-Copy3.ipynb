{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "# reading all our required datasets\n",
    "path = \"/home/subarna/Documents/vr/MT2019514_MT2019523_MT2019079/Part2/CIFAR-10-images-master/train\"\n",
    "filenames = glob.glob(path + \"/*\")\n",
    "df_train = []\n",
    "descriptor = []\n",
    "\n",
    "for filename in filenames:\n",
    "    clas_nams = glob.glob(filename + \"/*\")\n",
    "    for clas_nam in clas_nams:\n",
    "        try:\n",
    "            imageID = filename[filename.rfind(\"/\") + 1:]\n",
    "            img = cv2.imread(clas_nam)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            extractor = cv2.xfeatures2d.SIFT_create()\n",
    "            keypoints, descriptors = extractor.detectAndCompute(img, None)\n",
    "            descriptor.extend(descriptors)\n",
    "            df_train.append((imageID,descriptors))\n",
    "        except TypeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "# reading all our required datasets\n",
    "path = \"/home/subarna/Documents/vr/MT2019514_MT2019523_MT2019079/Part2/CIFAR-10-images-master/test\"\n",
    "filenames = glob.glob(path + \"/*\")\n",
    "df_test = []\n",
    "descriptor_test = []\n",
    "for filename in filenames:\n",
    "    clas_nams = glob.glob(filename + \"/*\")\n",
    "    for clas_nam in clas_nams:\n",
    "        try:\n",
    "            imageID = filename[filename.rfind(\"/\") + 1:]\n",
    "            img = cv2.imread(clas_nam)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            extractor = cv2.xfeatures2d.SIFT_create()\n",
    "            keypoints, descriptors = extractor.detectAndCompute(img, None)\n",
    "            descriptor_test.extend(descriptors)\n",
    "            df_test.append((imageID,descriptors))\n",
    "        except TypeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_train = np.array(descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(663279, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting our clusters and there centroids\n",
    "kmeans = KMeans(n_clusters = 40, random_state = 10)\n",
    "kmeans.fit(des_train)\n",
    "cluster = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=40, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=10, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.DataFrame(df_train)\n",
    "df_te = pd.DataFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {'dog' : 0, 'automobile' : 1, 'bird' : 2, 'airplane' : 3, 'ship' : 4, 'truck' : 5, 'frog' : 6, 'horse' : 7, 'deer' : 8, 'cat' : 9}\n",
    "df_tr[0] = [l[item] for item in df_tr[0]]\n",
    "df_te[0] = [l[item] for item in df_te[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_tr[0].to_numpy()\n",
    "y_test = df_te[0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(df_train[0][1][0], (1,128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq\n",
    "train_features = np.zeros((len(df_train), 40), \"float32\")\n",
    "for i in range(0,len(df_train)):\n",
    "    words, distance = vq(df_train[i][1],kmeans.cluster_centers_)\n",
    "    for w in words:\n",
    "        train_features[i][w] += 1\n",
    "\n",
    "test_features = np.zeros((len(df_test), 40), \"float32\")\n",
    "for i in range(0,len(df_test)):\n",
    "    words, distance = vq(df_test[i][1],kmeans.cluster_centers_)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preproceesing train and test dataset \n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#Perform Tf-Idf vectorization\n",
    "nbr_occurences = np.sum( (train_features > 0) * 1, axis = 0)\n",
    "# Calculating the number of occurrences\n",
    "idf = np.array(np.log((1.0*len(train_features)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "# Giving weight to one that occurs more frequently\n",
    "# Scaling the features\n",
    "stdSlr = StandardScaler().fit(train_features)\n",
    "im_features_train = stdSlr.transform(train_features)\n",
    "\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(test_features)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "stdSlr = StandardScaler().fit(test_features)\n",
    "im_features_test = stdSlr.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 19.00%\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=7,n_jobs=-1)\n",
    "model.fit(im_features_train, x_test)\n",
    "acc = model.score(im_features_test, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 19.45%\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=9,n_jobs=-1)\n",
    "model.fit(im_features_train, x_test)\n",
    "acc = model.score(im_features_test, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[('building', array([[ 0.,  0., 27., ..., 19.,  9.,  5.],\n",
    "         [ 0.,  0.,  0., ..., 17.,  3.,  0.],\n",
    "         [ 2.,  0.,  0., ...,  2., 27., 27.],\n",
    "         ...,\n",
    "         [ 4.,  5., 69., ...,  6.,  2.,  2.],\n",
    "         [48., 95.,  3., ...,  0., 19., 24.],\n",
    "         [ 0.,  0.,  1., ..., 11., 70., 23.]], dtype=float32)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([[ 8.260876 ,  8.000003 , 14.804345 , ..., 16.239134 ,  7.6739125,\n",
    "        11.413044 ],\n",
    "       [35.813564 , 17.271187 , 10.661015 , ..., 10.000004 ,  9.898304 ,\n",
    "        14.559323 ],\n",
    "       [37.456142 , 31.052639 , 18.421051 , ..., 19.859648 ,  8.087721 ,\n",
    "        18.789474 ],\n",
    "       ...,\n",
    "       [11.434788 ,  7.608696 , 32.565216 , ..., 14.782609 , 27.130432 ,\n",
    "        25.913044 ],\n",
    "       [ 5.511116 ,  9.044447 , 30.088886 , ...,  5.666665 ,  6.3555565,\n",
    "         6.3555555],\n",
    "       [41.431377 , 68.352936 , 46.07843  , ...,  8.803923 , 12.9803915,\n",
    "        19.784313 ]], dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster.shape\n",
    "(50, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_vlad = []\n",
    "for i in range(0,len(df_train)):\n",
    "    su = np.zeros((1,128))\n",
    "    for j in range(0,len(df_train[i][1])):\n",
    "        ind = kmeans.predict([df_train[i][1][j]])\n",
    "        x = df_train[i][1][j] - cluster[ind]\n",
    "        su += x\n",
    "    df_train_vlad.append(su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 128)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.79%\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear')\n",
    "model.fit(im_features_train, x_test)\n",
    "acc = model.score(im_features_test, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlad_features=[]\n",
    "for i in range(len(df_train)):\n",
    "    vlad_vector = np.zeros((40,128), \"float32\")\n",
    "    words, distance = vq(df_train[i][1],kmeans.cluster_centers_)\n",
    "    j=0\n",
    "    for w in words:\n",
    "        vlad_vector[w] = np.add(vlad_vector[w], np.subtract(df_train[i][1][j],kmeans.cluster_centers_[w]))\n",
    "        j = j+1\n",
    "    norm = np.linalg.norm(vlad_vector)\n",
    "    vlad_vector= np.divide(vlad_vector,norm)\n",
    "    vlad_vector= vlad_vector.flatten()\n",
    "    vlad_features.append(vlad_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlad_features_test=[]\n",
    "for i in range(len(df_test)):\n",
    "    vlad_vector = np.zeros((40,128), \"float32\")\n",
    "    words, distance = vq(df_test[i][1],kmeans.cluster_centers_)\n",
    "    j=0\n",
    "    for w in words:\n",
    "        vlad_vector[w] = np.add(vlad_vector[w], np.subtract(df_test[i][1][j],kmeans.cluster_centers_[w]))\n",
    "        j = j+1\n",
    "    norm = np.linalg.norm(vlad_vector)\n",
    "    vlad_vector= np.divide(vlad_vector,norm)\n",
    "    vlad_vector= vlad_vector.flatten()\n",
    "    vlad_features_test.append(vlad_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.96%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(vlad_features, x_test)\n",
    "acc = model.score(vlad_features_test, y_test)\n",
    "print(\"Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
